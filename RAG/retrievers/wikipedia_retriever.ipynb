{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cb10cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "856c757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = WikipediaRetriever(top_k_results=2 , lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72917062",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is LangChain?\"\n",
    "\n",
    "docs = retriever.invoke(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79d5f6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'Milvus (vector database)', 'summary': 'Milvus is a distributed vector database developed by Zilliz. It is available as both open-source software and a cloud service called Zilliz Cloud.\\nMilvus is an open-source project under the LF AI & Data Foundation and is distributed under the Apache License 2.0.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Milvus_(vector_database)'}, page_content=\"Milvus is a distributed vector database developed by Zilliz. It is available as both open-source software and a cloud service called Zilliz Cloud.\\nMilvus is an open-source project under the LF AI & Data Foundation and is distributed under the Apache License 2.0.\\n\\n\\n== History ==\\nMilvus has been developed by Zilliz since 2017.\\nMilvus joined Linux Foundation as an incubation project in January 2020 and became a graduate in June 2021. The details about its architecture and possible applications were presented at ACM SIGMOD Conference in 2021.\\nMilvus 2.0, a major redesign of the whole product with a new architecture, was released in January 2022.\\n\\n\\n== Features ==\\n\\n\\n=== Similarity search ===\\nVarious similarity search-related features are available in Milvus:\\n\\nIn-memory, on-disk and GPU indices,\\nSingle query, batch query and range query search,\\nSupport of sparse vectors, binary vectors, JSON and arrays,\\nFP32, FP16 and BF16 data types,\\nEuclidean distance, inner product distance and cosine distance support for floating-point data,\\nHamming distance and jaccard distance for binary data,\\nSupport of graph indices (including HNSW), Inverted-lists based indices and a brute-force search.\\nSupport of vector quantization for lossy input data compression, including product quantization (PQ) and scalar quantization (SQ), that trades stored data size for accuracy,\\nRe-ranking.\\nMilvus' similarity search engine relies on heavily-modified forks of third-party open-source similarity search libraries, such as Faiss, DiskANN and hnswlib.\\nMilvus includes optimizations for I/O data layout, specific to graph search indices.\\n\\n\\n=== Database ===\\nAs a database, Milvus provides the following features:\\n\\nSupport for column-oriented databases\\nFour supported data consistency levels, including strong consistency and eventual consistency\\nData sharding\\nStreaming data ingestion, which allows processing and ingestion of data in real-time as it arrives\\nA dynamic schema, which allows insertion of data without a predefined schema\\nIndependent storage and compute layers\\nSupport for multi-tenancy scenarios (database-oriented, collection-oriented, partition-oriented)\\nMemory-mapped data storage\\nRole-based access control\\nMulti-vector and hybrid search\\n\\n\\n=== Deployment options ===\\nMilvus can be deployed as an embedded database, standalone server, or distributed cluster. Zilliz Cloud offers a fully managed version.\\n\\n\\n=== GPU support ===\\nMilvus provides GPU accelerated index building and search using Nvidia CUDA technology via the Nvidia cuVS library, including a recent GPU-based graph indexing algorithm known as CAGRA.\\n\\n\\n=== Integration ===\\nMilvus provides official SDK clients for Java, NodeJS, Python and Go. An additional C# SDK client was contributed by Microsoft. The database can integrate with DataDog, Prometheus and Grafana for monitoring and alerts, as well as generative AI frameworks Haystack, LangChain, IBM Watsonx, and those provided by OpenAI.\\nSeveral storage providers have built integrations with Milvus to support AI workloads and large-scale vector search. These integrations aim to optimize performance, simplify inferencing workflows, and enhance data management capabilities:\\n\\nPure Storage\\nCloudian\\nWeka.io\\nDDN\\n\\n\\n== See also ==\\n\\nNearest neighbor search\\nSimilarity search\\nVector database\\nVector embedding\\nVector quantization\\n\\n\\n== References ==\\n\\n\\n== External links ==\\nOfficial website\\nmilvus on GitHub\"),\n",
       " Document(metadata={'title': 'Markov chain', 'summary': 'In probability theory and statistics, a Markov chain or Markov process is a stochastic process describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. Informally, this may be thought of as, \"What happens next depends only on the state of affairs now.\" A countably infinite sequence, in which the chain moves state at discrete time steps, gives a discrete-time Markov chain (DTMC). A continuous-time process is called a continuous-time Markov chain (CTMC). Markov processes are named in honor of the Russian mathematician Andrey Markov.\\nMarkov chains have many applications as statistical models of real-world processes. They provide the basis for general stochastic simulation methods known as Markov chain Monte Carlo, which are used for simulating sampling from complex probability distributions, and have found application in areas including Bayesian statistics, biology, chemistry, economics, finance, information theory, physics, signal processing, and speech processing.\\nThe adjectives Markovian and Markov are used to describe something that is related to a Markov process.', 'source': 'https://en.wikipedia.org/wiki/Markov_chain'}, page_content='In probability theory and statistics, a Markov chain or Markov process is a stochastic process describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. Informally, this may be thought of as, \"What happens next depends only on the state of affairs now.\" A countably infinite sequence, in which the chain moves state at discrete time steps, gives a discrete-time Markov chain (DTMC). A continuous-time process is called a continuous-time Markov chain (CTMC). Markov processes are named in honor of the Russian mathematician Andrey Markov.\\nMarkov chains have many applications as statistical models of real-world processes. They provide the basis for general stochastic simulation methods known as Markov chain Monte Carlo, which are used for simulating sampling from complex probability distributions, and have found application in areas including Bayesian statistics, biology, chemistry, economics, finance, information theory, physics, signal processing, and speech processing.\\nThe adjectives Markovian and Markov are used to describe something that is related to a Markov process.\\n\\n\\n== Principles ==\\n\\n\\n=== Definition ===\\nA Markov process is a stochastic process that satisfies the Markov property (sometimes characterized as \"memorylessness\"). In simpler terms, it is a process for which predictions can be made regarding future outcomes based solely on its present state and—most importantly—such predictions are just as good as the ones that could be made knowing the process\\'s full history. In other words, conditional on the present state of the system, its future and past states are independent.\\nA Markov chain is a type of Markov process that has either a discrete state space or a discrete index set (often representing time), but the precise definition of a Markov chain varies. For example, it is common to define a Markov chain as a Markov process in either discrete or continuous time with a countable state space (thus regardless of the nature of time), but it is also common to define a Markov chain as having discrete time in either countable or continuous state space (thus regardless of the state space).\\n\\n\\n=== Types of Markov chains ===\\nThe system\\'s state space and time parameter index need to be specified. The following table gives an overview of the different instances of Markov processes for different levels of state space generality and for discrete time v. continuous time:\\n\\nNote that there is no definitive agreement in the literature on the use of some of the terms that signify special cases of Markov processes. Usually the term \"Markov chain\" is reserved for a process with a discrete set of times, that is, a discrete-time Markov chain (DTMC), but a few authors use the term \"Markov process\" to refer to a continuous-time Markov chain (CTMC) without explicit mention. In addition, there are other extensions of Markov processes that are referred to as such but do not necessarily fall within any of these four categories (see Markov model). Moreover, the time index need not necessarily be real-valued; like with the state space, there are conceivable processes that move through index sets with other mathematical constructs. Notice that the general state space continuous-time Markov chain is general to such a degree that it has no designated term.\\nWhile the time parameter is usually discrete, the state space of a Markov chain does not have any generally agreed-on restrictions: the term may refer to a process on an arbitrary state space. However, many applications of Markov chains employ finite or countably infinite state spaces, which have a more straightforward statistical analysis. Besides time-index and state-space parameters, there are many other variations, extensions and generalizations (see Variations). For simplicity, most of this article concentrates on the discrete-time, discrete state-space case, unless mentioned otherwise.\\n\\n\\n=== Transitions ===\\nThe changes ')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a9e4995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "Milvus is a distributed vector database developed by Zilliz. It is available as both open-source software and a cloud service called Zilliz Cloud.\n",
      "Milvus is an open-source project under the LF AI & Data Foundation and is distributed under the Apache License 2.0.\n",
      "\n",
      "\n",
      "== History ==\n",
      "Milvus has been developed by Zilliz since 2017.\n",
      "Milvus joined Linux Foundation as an incubation project in January 2020 and became a graduate in June 2021. The details about its architecture and possible applications were presented at ACM SIGMOD Conference in 2021.\n",
      "Milvus 2.0, a major redesign of the whole product with a new architecture, was released in January 2022.\n",
      "\n",
      "\n",
      "== Features ==\n",
      "\n",
      "\n",
      "=== Similarity search ===\n",
      "Various similarity search-related features are available in Milvus:\n",
      "\n",
      "In-memory, on-disk and GPU indices,\n",
      "Single query, batch query and range query search,\n",
      "Support of sparse vectors, binary vectors, JSON and arrays,\n",
      "FP32, FP16 and BF16 data types,\n",
      "Euclidean distance, inner product distance and cosine distance support for floating-point data,\n",
      "Hamming distance and jaccard distance for binary data,\n",
      "Support of graph indices (including HNSW), Inverted-lists based indices and a brute-force search.\n",
      "Support of vector quantization for lossy input data compression, including product quantization (PQ) and scalar quantization (SQ), that trades stored data size for accuracy,\n",
      "Re-ranking.\n",
      "Milvus' similarity search engine relies on heavily-modified forks of third-party open-source similarity search libraries, such as Faiss, DiskANN and hnswlib.\n",
      "Milvus includes optimizations for I/O data layout, specific to graph search indices.\n",
      "\n",
      "\n",
      "=== Database ===\n",
      "As a database, Milvus provides the following features:\n",
      "\n",
      "Support for column-oriented databases\n",
      "Four supported data consistency levels, including strong consistency and eventual consistency\n",
      "Data sharding\n",
      "Streaming data ingestion, which allows processing and ingestion of data in real-time as it arrives\n",
      "A dynamic schema, which allows insertion of data without a predefined schema\n",
      "Independent storage and compute layers\n",
      "Support for multi-tenancy scenarios (database-oriented, collection-oriented, partition-oriented)\n",
      "Memory-mapped data storage\n",
      "Role-based access control\n",
      "Multi-vector and hybrid search\n",
      "\n",
      "\n",
      "=== Deployment options ===\n",
      "Milvus can be deployed as an embedded database, standalone server, or distributed cluster. Zilliz Cloud offers a fully managed version.\n",
      "\n",
      "\n",
      "=== GPU support ===\n",
      "Milvus provides GPU accelerated index building and search using Nvidia CUDA technology via the Nvidia cuVS library, including a recent GPU-based graph indexing algorithm known as CAGRA.\n",
      "\n",
      "\n",
      "=== Integration ===\n",
      "Milvus provides official SDK clients for Java, NodeJS, Python and Go. An additional C# SDK client was contributed by Microsoft. The database can integrate with DataDog, Prometheus and Grafana for monitoring and alerts, as well as generative AI frameworks Haystack, LangChain, IBM Watsonx, and those provided by OpenAI.\n",
      "Several storage providers have built integrations with Milvus to support AI workloads and large-scale vector search. These integrations aim to optimize performance, simplify inferencing workflows, and enhance data management capabilities:\n",
      "\n",
      "Pure Storage\n",
      "Cloudian\n",
      "Weka.io\n",
      "DDN\n",
      "\n",
      "\n",
      "== See also ==\n",
      "\n",
      "Nearest neighbor search\n",
      "Similarity search\n",
      "Vector database\n",
      "Vector embedding\n",
      "Vector quantization\n",
      "\n",
      "\n",
      "== References ==\n",
      "\n",
      "\n",
      "== External links ==\n",
      "Official website\n",
      "milvus on GitHub\n",
      "\n",
      "\n",
      "\n",
      "Document 2:\n",
      "In probability theory and statistics, a Markov chain or Markov process is a stochastic process describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. Informally, this may be thought of as, \"What happens next depends only on the state of affairs now.\" A countably infinite sequence, in which the chain moves state at discrete time steps, gives a discrete-time Markov chain (DTMC). A continuous-time process is called a continuous-time Markov chain (CTMC). Markov processes are named in honor of the Russian mathematician Andrey Markov.\n",
      "Markov chains have many applications as statistical models of real-world processes. They provide the basis for general stochastic simulation methods known as Markov chain Monte Carlo, which are used for simulating sampling from complex probability distributions, and have found application in areas including Bayesian statistics, biology, chemistry, economics, finance, information theory, physics, signal processing, and speech processing.\n",
      "The adjectives Markovian and Markov are used to describe something that is related to a Markov process.\n",
      "\n",
      "\n",
      "== Principles ==\n",
      "\n",
      "\n",
      "=== Definition ===\n",
      "A Markov process is a stochastic process that satisfies the Markov property (sometimes characterized as \"memorylessness\"). In simpler terms, it is a process for which predictions can be made regarding future outcomes based solely on its present state and—most importantly—such predictions are just as good as the ones that could be made knowing the process's full history. In other words, conditional on the present state of the system, its future and past states are independent.\n",
      "A Markov chain is a type of Markov process that has either a discrete state space or a discrete index set (often representing time), but the precise definition of a Markov chain varies. For example, it is common to define a Markov chain as a Markov process in either discrete or continuous time with a countable state space (thus regardless of the nature of time), but it is also common to define a Markov chain as having discrete time in either countable or continuous state space (thus regardless of the state space).\n",
      "\n",
      "\n",
      "=== Types of Markov chains ===\n",
      "The system's state space and time parameter index need to be specified. The following table gives an overview of the different instances of Markov processes for different levels of state space generality and for discrete time v. continuous time:\n",
      "\n",
      "Note that there is no definitive agreement in the literature on the use of some of the terms that signify special cases of Markov processes. Usually the term \"Markov chain\" is reserved for a process with a discrete set of times, that is, a discrete-time Markov chain (DTMC), but a few authors use the term \"Markov process\" to refer to a continuous-time Markov chain (CTMC) without explicit mention. In addition, there are other extensions of Markov processes that are referred to as such but do not necessarily fall within any of these four categories (see Markov model). Moreover, the time index need not necessarily be real-valued; like with the state space, there are conceivable processes that move through index sets with other mathematical constructs. Notice that the general state space continuous-time Markov chain is general to such a degree that it has no designated term.\n",
      "While the time parameter is usually discrete, the state space of a Markov chain does not have any generally agreed-on restrictions: the term may refer to a process on an arbitrary state space. However, many applications of Markov chains employ finite or countably infinite state spaces, which have a more straightforward statistical analysis. Besides time-index and state-space parameters, there are many other variations, extensions and generalizations (see Variations). For simplicity, most of this article concentrates on the discrete-time, discrete state-space case, unless mentioned otherwise.\n",
      "\n",
      "\n",
      "=== Transitions ===\n",
      "The changes \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i , doc in enumerate(docs):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(doc.page_content)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58db47e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
